{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:15:57.802714Z",
     "iopub.status.busy": "2024-12-12T07:15:57.802510Z",
     "iopub.status.idle": "2024-12-12T07:16:01.357351Z",
     "shell.execute_reply": "2024-12-12T07:16:01.356664Z",
     "shell.execute_reply.started": "2024-12-12T07:15:57.802698Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#from sklearn.metrics import accuracy_score, log_loss\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.optim import Adam, SGD\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "#import functools\n",
    "#import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 1001\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:01.358801Z",
     "iopub.status.busy": "2024-12-12T07:16:01.358206Z",
     "iopub.status.idle": "2024-12-12T07:16:01.637296Z",
     "shell.execute_reply": "2024-12-12T07:16:01.636375Z",
     "shell.execute_reply.started": "2024-12-12T07:16:01.358781Z"
    },
    "id": "9rEyke1quwOa",
    "outputId": "b5ce88a4-4736-423f-835f-a93a3560be5b"
   },
   "outputs": [],
   "source": [
    "import torchquantum as tq\n",
    "from torchquantum.measurement import expval_joint_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:01.639241Z",
     "iopub.status.busy": "2024-12-12T07:16:01.638909Z",
     "iopub.status.idle": "2024-12-12T07:16:01.642920Z",
     "shell.execute_reply": "2024-12-12T07:16:01.642336Z",
     "shell.execute_reply.started": "2024-12-12T07:16:01.639222Z"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(tq.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:01.643897Z",
     "iopub.status.busy": "2024-12-12T07:16:01.643690Z",
     "iopub.status.idle": "2024-12-12T07:16:02.603107Z",
     "shell.execute_reply": "2024-12-12T07:16:02.602248Z",
     "shell.execute_reply.started": "2024-12-12T07:16:01.643882Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "print(n_gpu)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print([torch.cuda.get_device_name('cuda:'+str(i)) for i in range(n_gpu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:02.604342Z",
     "iopub.status.busy": "2024-12-12T07:16:02.604153Z",
     "iopub.status.idle": "2024-12-12T07:16:02.934916Z",
     "shell.execute_reply": "2024-12-12T07:16:02.934255Z",
     "shell.execute_reply.started": "2024-12-12T07:16:02.604327Z"
    }
   },
   "outputs": [],
   "source": [
    "data = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "data_tr, label_tr = data.train_data, data.train_labels\n",
    "data = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "data_te, label_te = data.test_data, data.test_labels\n",
    "print(data_tr.shape, data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:02.936394Z",
     "iopub.status.busy": "2024-12-12T07:16:02.935670Z",
     "iopub.status.idle": "2024-12-12T07:16:03.494223Z",
     "shell.execute_reply": "2024-12-12T07:16:03.493637Z",
     "shell.execute_reply.started": "2024-12-12T07:16:02.936344Z"
    }
   },
   "outputs": [],
   "source": [
    "num = 10\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(2,num//2,i+1)\n",
    "    ax.imshow(data_tr[i].detach().numpy(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.495171Z",
     "iopub.status.busy": "2024-12-12T07:16:03.495033Z",
     "iopub.status.idle": "2024-12-12T07:16:03.499165Z",
     "shell.execute_reply": "2024-12-12T07:16:03.498686Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.495164Z"
    },
    "id": "1cyWO0H6KHts",
    "outputId": "e1a34cbd-64b0-4d49-b783-23a0860b3484"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'mnist'\n",
    "n_class = len(np.unique(label_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 8\n",
    "n_half_qubits = n_qubits//2 # 4\n",
    "n_latter_half_qubits = n_qubits-n_half_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.503347Z",
     "iopub.status.busy": "2024-12-12T07:16:03.503066Z",
     "iopub.status.idle": "2024-12-12T07:16:03.506454Z",
     "shell.execute_reply": "2024-12-12T07:16:03.506109Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.503291Z"
    },
    "id": "1BM-C_Bk9ABt"
   },
   "outputs": [],
   "source": [
    "class ConstCoeffLayer(nn.Module):\n",
    "    def __init__(self, coeff):\n",
    "        super().__init__()\n",
    "        self.coeff = coeff\n",
    "    def forward(self, x):\n",
    "        ret = x * self.coeff\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.508452Z",
     "iopub.status.busy": "2024-12-12T07:16:03.507965Z",
     "iopub.status.idle": "2024-12-12T07:16:03.513136Z",
     "shell.execute_reply": "2024-12-12T07:16:03.512780Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.508436Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_exp_val(qdev, obs):\n",
    "    assert len(obs)==n_qubits\n",
    "    state2 = qdev.states.clone()\n",
    "    for i in range(n_qubits):\n",
    "        if obs[i]=='I':\n",
    "            continue\n",
    "        elif obs[i]=='X':\n",
    "            mat = torch.tensor([[0,1],[1,0]])\n",
    "        elif obs[i]=='Y':\n",
    "            mat = torch.tensor([[0,-1j],[1j,0]])\n",
    "        elif obs[i]=='Z':\n",
    "            mat = torch.tensor([[1,0],[0,-1]])\n",
    "        state2 = tq.functional.apply_unitary_bmm(state2, mat, [i])\n",
    "    state1 = qdev.states.clone()\n",
    "    exp_val = torch.einsum(\"bij...k,bij...k->b\", state1.conj(), state2).real\n",
    "    # to confirm the calculation of expectation values\n",
    "    if False:\n",
    "        bra = qdev.get_states_1d().clone().conj()\n",
    "        ket = torch.reshape(state2, [bsz, 2**n_qubits])\n",
    "        tmp_exp_val = torch.sum(bra*ket,dim=1).real # (bsz,dim) => (bsz)\n",
    "        assert np.allclose(tmp_exp_val.detach().cpu().numpy(),exp_val.detach().cpu().numpy(),rtol=1e-5,atol=1e-5)\n",
    "    return exp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14x14 => 7x14x2\n",
    "# 2n_qubitsx28 => 14x7x8 = 14x28x2\n",
    "class QNNsubModel(nn.Module):\n",
    "    def __init__(self,n_depth_per_block):\n",
    "        # params is numpy array\n",
    "        super().__init__()\n",
    "        self.n_depth_per_block = n_depth_per_block\n",
    "    def forward(self, x, phi):\n",
    "        bsz, nx_features = x.shape\n",
    "        qdev = tq.QuantumDevice(\n",
    "            n_wires=n_qubits, bsz = bsz, device=x.device, record_op=False\n",
    "        )\n",
    "        n_depth_per_block = self.n_depth_per_block\n",
    "        for k in range(n_depth_per_block):\n",
    "            # j = 2*d*n_depth_per_block + 2*k\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.rx(qdev, wires=i, params=phi[i+2*k*n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.ry(qdev, wires=i, params=phi[i+(2*k+1)*n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                qdev.cz(wires=[i,(i+1)%n_qubits])\n",
    "        for i in range(n_qubits): # x: 32, phi: 64\n",
    "            for j in range(n_half_qubits):\n",
    "                if j%2==0:\n",
    "                    tq.functional.ry(qdev, wires=i, params=phi[2*n_half_qubits*i+2*j+2*n_depth_per_block*n_qubits])\n",
    "                    tq.functional.rx(qdev, wires=i, params=x[:,n_half_qubits*i+j]) ##\n",
    "                    tq.functional.ry(qdev, wires=i, params=phi[2*n_half_qubits*i+2*j+1+2*n_depth_per_block*n_qubits])\n",
    "                else:\n",
    "                    tq.functional.rx(qdev, wires=i, params=phi[2*n_half_qubits*i+2*j+2*n_depth_per_block*n_qubits])\n",
    "                    tq.functional.ry(qdev, wires=i, params=x[:,n_half_qubits*i+j]) ##\n",
    "                    tq.functional.rx(qdev, wires=i, params=phi[2*n_half_qubits*i+2*j+1+2*n_depth_per_block*n_qubits])\n",
    "        for i in range(n_qubits):\n",
    "            qdev.cz(wires=[i,(i+1)%(n_qubits)])\n",
    "        for k in range(n_depth_per_block):\n",
    "            # j = 2*d*n_depth_per_block + 2*k\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.rx(qdev, wires=i, params=phi[i+(2*n_depth_per_block+2*n_half_qubits +2*k)*n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.ry(qdev, wires=i, params=phi[i+(2*n_depth_per_block+2*n_half_qubits +2*k+1)*n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                qdev.cz(wires=[i,(i+1)%n_qubits])\n",
    "        for i in range(n_qubits): # 32, 64\n",
    "            for j in range(n_latter_half_qubits):\n",
    "                if j%2==0:\n",
    "                    tq.functional.ry(qdev, wires=i, params=phi[2*n_latter_half_qubits*i+2*j+2*n_half_qubits*n_qubits+4*n_depth_per_block*n_qubits])\n",
    "                    tq.functional.rx(qdev, wires=i, params=x[:,n_latter_half_qubits*i+j+n_half_qubits*n_qubits]) ##\n",
    "                    tq.functional.ry(qdev, wires=i, params=phi[2*n_latter_half_qubits*i+2*j+1+2*n_half_qubits*n_qubits+4*n_depth_per_block*n_qubits])\n",
    "                else:\n",
    "                    tq.functional.rx(qdev, wires=i, params=phi[2*n_latter_half_qubits*i+2*j+2*n_half_qubits*n_qubits+4*n_depth_per_block*n_qubits])\n",
    "                    tq.functional.ry(qdev, wires=i, params=x[:,n_latter_half_qubits*i+j+n_half_qubits*n_qubits]) ##\n",
    "                    tq.functional.rx(qdev, wires=i, params=phi[2*n_latter_half_qubits*i+2*j+1+2*n_half_qubits*n_qubits+4*n_depth_per_block*n_qubits])\n",
    "        for i in range(n_qubits):\n",
    "            qdev.cz(wires=[i,(i+1)%(n_qubits)])\n",
    "        j= 2\n",
    "        for k in range(n_depth_per_block):\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.rx(qdev, wires=i, params=phi[i+(4*n_depth_per_block+2*n_qubits +2*k)*n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                tq.functional.ry(qdev, wires=i, params=phi[i+(4*n_depth_per_block+2*n_qubits +2*k+1)*n_qubits])\n",
    "            if (k==n_depth_per_block-1):\n",
    "                break\n",
    "            for i in range(n_qubits):\n",
    "                qdev.cz(wires=[i,(i+1)%n_qubits])\n",
    "        obs_list = [ calc_exp_val(qdev, \"I\"*i+Pauli+\"I\"*(n_qubits-1-i)) for Pauli in [\"X\",\"Z\"] for i in range(n_class//2)]\n",
    "        ret = torch.stack(obs_list, dim=1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.528164Z",
     "iopub.status.busy": "2024-12-12T07:16:03.527904Z",
     "iopub.status.idle": "2024-12-12T07:16:03.532943Z",
     "shell.execute_reply": "2024-12-12T07:16:03.532555Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.528164Z"
    }
   },
   "outputs": [],
   "source": [
    "# 14x14 => 7x14x2\n",
    "# 1:8, 7:14 -> 0:7, 6:13\n",
    "# 1:8, 4:11, 7:14 -> 0:7, 3:10, 6:13\n",
    "class QNNModel(nn.Module):\n",
    "    def __init__(self,n_qnn,n_depth_per_block):\n",
    "        super().__init__()\n",
    "        self.n_qnn = n_qnn\n",
    "        self.n_depth_per_block = n_depth_per_block\n",
    "        self.params_list = nn.ParameterList([torch.rand( (3*2*n_depth_per_block+2*n_qubits)*n_qubits )*math.pi for _ in range(n_qnn)])\n",
    "        self.pos_bias = nn.Parameter( torch.zeros(14, 14, device=device) )\n",
    "        self.qnn_list = [QNNsubModel(n_depth_per_block) for _ in range(n_qnn)]\n",
    "        self.qnn_index_list = [i for i in range(0,7,6//int(np.sqrt(n_qnn)-1))]\n",
    "    def forward(self, x):\n",
    "        n_data = len(x)\n",
    "        in_x = x + self.pos_bias\n",
    "        in_x = torch.stack([ in_x[:,i:i+n_qubits,j:j+n_qubits].reshape(n_data,n_qubits*n_qubits) for i in self.qnn_index_list for j in self.qnn_index_list ], axis=0) # (4,n_data,64)\n",
    "        ret_list = [checkpoint.checkpoint(self.qnn_list[i], in_x[i], self.params_list[i]) for i in range(self.n_qnn)]\n",
    "        ret = torch.stack(ret_list, axis=1) # (bsz, n_qnn, n_class)\n",
    "        ret = torch.mean(ret, axis=1) # (bsz,n_class)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.534109Z",
     "iopub.status.busy": "2024-12-12T07:16:03.533519Z",
     "iopub.status.idle": "2024-12-12T07:16:03.538288Z",
     "shell.execute_reply": "2024-12-12T07:16:03.537924Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.534092Z"
    },
    "id": "vwqhXVC1vMDj"
   },
   "outputs": [],
   "source": [
    "def train(data, label, model, accumulation_steps):\n",
    "    pred = model(data) # (bsz, n_class)\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
    "    loss = loss / accumulation_steps\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        pred_normalized = nn.functional.softmax(pred, dim=1)\n",
    "        acc = (pred_normalized.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    print(f\"train loss: {loss.item()*accumulation_steps:.5f} train acc: {acc:.3f}\", end='\\n')\n",
    "    return loss.item(), acc\n",
    "\n",
    "def valid(data, label, model):\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
    "        pred_normalized = nn.functional.softmax(pred, dim=1)\n",
    "        acc = (pred_normalized.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    print(f\"valid loss: {loss.item():.5f} valid acc: {acc:.3f}\", end='\\n')\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.539218Z",
     "iopub.status.busy": "2024-12-12T07:16:03.538953Z",
     "iopub.status.idle": "2024-12-12T07:16:03.736654Z",
     "shell.execute_reply": "2024-12-12T07:16:03.736208Z",
     "shell.execute_reply.started": "2024-12-12T07:16:03.539218Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tr = data_tr/255*2*math.pi/n_qubits\n",
    "data_te = data_te/255*2*math.pi/n_qubits\n",
    "\n",
    "data_tr = torch.nn.AvgPool2d( (2,2), stride=(2,2) )(data_tr) # (28,28) -> (14,14)\n",
    "data_te = torch.nn.AvgPool2d( (2,2), stride=(2,2) )(data_te) # (28,28) -> (14,14)\n",
    "\n",
    "#data_tr = data_tr.reshape(-1,data_tr.shape[1]*data_tr.shape[2]) #.detach().numpy()\n",
    "#data_te = data_te.reshape(-1,data_te.shape[1]*data_te.shape[2]) #.detach().numpy()\n",
    "print(data_tr.shape, data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-12T07:16:03.738023Z",
     "iopub.status.busy": "2024-12-12T07:16:03.737514Z"
    },
    "id": "mj_O5gA1LZMs",
    "outputId": "d3a6fccd-d75d-4265-9c1a-7e8275405cd5"
   },
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "coeff=100\n",
    "data_tr, label_tr = data_tr.to(device), label_tr.to(device)\n",
    "data_te, label_te = data_te.to(device), label_te.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_qnn in [4,9,16]:\n",
    "    for n_depth_per_block in [50,100,150,200]:\n",
    "        model = torch.nn.Sequential( QNNModel(n_qnn, n_depth_per_block), ConstCoeffLayer(coeff) )\n",
    "        if n_depth_per_block==50:\n",
    "            dir_name = 'tmp_8qubits_'+str(n_qnn)+'qnn'\n",
    "        else:\n",
    "            dir_name = 'tmp_8qubits_'+str(n_qnn)+'qnn'+str(n_depth_per_block)\n",
    "\n",
    "        #if ((n_qnn==4 or n_qnn==9) and n_depth_per_block==50)or(n_qnn==4 and n_depth_per_block==100):\n",
    "        #    prefix_name = ''\n",
    "        #else:\n",
    "        prefix_name = \"mnist_\"+str(n_qnn)+\"qnn\"+str(n_depth_per_block)+\"_c100_8qubits_ensembling_cos\"\n",
    "        model.load_state_dict(torch.load(dir_name+'/'+prefix_name+'_init.pt', weights_only=True))\n",
    "        loss_tr_list = []\n",
    "        loss_te_list = []\n",
    "        acc_tr_list = []\n",
    "        acc_te_list = []\n",
    "        with torch.no_grad():\n",
    "            pred_tr = model(data_tr)\n",
    "            loss = torch.nn.CrossEntropyLoss()(pred_tr, label_tr)\n",
    "            loss_tr_list.append(loss.item())\n",
    "            pred_tr_normalized = nn.functional.softmax(pred_tr, dim=1)\n",
    "            acc_tr = (pred_tr_normalized.argmax(axis=1) == label_tr).sum().item() / len(label_tr)\n",
    "            acc_tr_list.append(acc_tr)\n",
    "            time.sleep(10)\n",
    "            pred_te = model(data_te)\n",
    "            loss = torch.nn.CrossEntropyLoss()(pred_te, label_te)\n",
    "            loss_te_list.append(loss.item())\n",
    "            pred_te_normalized = nn.functional.softmax(pred_te, dim=1)\n",
    "            acc_te= (pred_te_normalized.argmax(axis=1) == label_te).sum().item() / len(label_te)\n",
    "            acc_te_list.append(acc_te)\n",
    "            time.sleep(10)\n",
    "        for epoch_i in tqdm(range(max_epochs)):\n",
    "            model.load_state_dict(torch.load(dir_name+'/'+prefix_name+'_epoch'+str(epoch_i)+'.pt', weights_only=True))\n",
    "            pred_tr = model(data_tr)\n",
    "            loss = torch.nn.CrossEntropyLoss()(pred_tr, label_tr)\n",
    "            loss_tr_list.append(loss.item())\n",
    "            pred_tr_normalized = nn.functional.softmax(pred_tr, dim=1)\n",
    "            acc_tr = (pred_tr_normalized.argmax(axis=1) == label_tr).sum().item() / len(label_tr)\n",
    "            acc_tr_list.append(acc_tr)\n",
    "            time.sleep(10)\n",
    "            pred_te = model(data_te)\n",
    "            loss = torch.nn.CrossEntropyLoss()(pred_te, label_te)\n",
    "            loss_te_list.append(loss.item())\n",
    "            pred_te_normalized = nn.functional.softmax(pred_te, dim=1)\n",
    "            acc_te= (pred_te_normalized.argmax(axis=1) == label_te).sum().item() / len(label_te)\n",
    "            acc_te_list.append(acc_te)\n",
    "            time.sleep(10)\n",
    "        loss_tr_np = np.array(loss_tr_list)\n",
    "        loss_te_np = np.array(loss_te_list)\n",
    "        acc_tr_np = np.array(acc_tr_list)\n",
    "        acc_te_np = np.array(acc_te_list)\n",
    "        LEN = len(loss_tr_np)\n",
    "        pd.DataFrame({'epochs': np.arange(LEN)-1, 'train_loss': loss_tr_np, 'test_loss': loss_te_np, \\\n",
    "                    'train_acc': acc_tr_np, 'test_acc': acc_te_np\n",
    "                    }).to_csv(dir_name+'/'+prefix_name+'_loss_acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
